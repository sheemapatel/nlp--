{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheemapatel/nlp--/blob/main/22_8_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU7tP8uRjhQw",
        "outputId": "08b1244b-fd43-4aa9-c660-9f99fd80c5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### First 5 entries of 'text_1' (Before Cleaning) ###\n",
            "Japan economy slides to recession. The Japanese...\n",
            "Optimism remains over UK housing. The UK proper...\n",
            "Lufthansa flies back to profit. German airline ...\n",
            "      The quick brown fox jumps over the lazy dog.\n",
            "     A study found that 10% of users never log in.\n",
            "\n",
            "### Checking for Null Values ###\n",
            "text_1    1\n",
            "text_2    0\n",
            "dtype: int64\n",
            "\n",
            "DataFrame size before cleaning: 7\n",
            "DataFrame size after cleaning: 6\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    \"text_1\": [\n",
        "        \"Japan economy slides to recession. The Japanese economy has officially gone back into recession for the first time since 2001.\",\n",
        "        \"Optimism remains over UK housing. The UK property market remains robust despite the recent slowdown.\",\n",
        "        \"Lufthansa flies back to profit. German airline Lufthansa has returned to profit in 2004 after posting a loss in 2003.\",\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"A study found that 10% of users never log in.\",\n",
        "        np.nan,\n",
        "        \"This is another example text for cleaning.\"\n",
        "    ],\n",
        "    \"text_2\": [\n",
        "        \"Japan economy slides to recession the japanese economy has officially gone back into recession for t\",\n",
        "        \"The UK property market remains robust despite the recent slowdown.\",\n",
        "        \"German airline Lufthansa has returned to profit in 2004 after posting\",\n",
        "        \"The fast brown fox leaps over the lethargic canine.\",\n",
        "        \"10% of users never log in, a study found.\",\n",
        "        \"A paired text.\",\n",
        "        \"More text.\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"### First 5 entries of 'text_1' (Before Cleaning) ###\")\n",
        "print(df['text_1'].head().to_string(index=False))\n",
        "\n",
        "print(\"\\n### Checking for Null Values ###\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df_cleaned = df.dropna()\n",
        "print(f\"\\nDataFrame size before cleaning: {len(df)}\")\n",
        "print(f\"DataFrame size after cleaning: {len(df_cleaned)}\")\n",
        "\n",
        "pos_sentences = df_cleaned['text_1'].head(5).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "\n",
        "    nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "all_nouns = set()\n",
        "all_verbs = set()\n",
        "all_adjectives = set()\n",
        "\n",
        "for i, sentence in enumerate(pos_sentences):\n",
        "    doc = nlp(sentence)\n",
        "    print(f\"\\n--- Sentence {i+1} ---: **{sentence}**\")\n",
        "\n",
        "    print(\"{:<15} {:<10} {:<10}\".format(\"Token\", \"POS\", \"Dependency\"))\n",
        "    print(\"-\" * 35)\n",
        "    for token in doc:\n",
        "        print(\"{:<15} {:<10} {:<10}\".format(token.text, token.pos_, token.dep_))\n",
        "\n",
        "        if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
        "            all_nouns.add(token.text)\n",
        "        elif token.pos_ == \"VERB\":\n",
        "            all_verbs.add(token.text)\n",
        "        elif token.pos_ == \"ADJ\":\n",
        "            all_adjectives.add(token.text)\n",
        "\n",
        "print(\"\\n### Extracted Parts of Speech ###\")\n",
        "print(f\"**Nouns**: {sorted(list(all_nouns))}\")\n",
        "print(f\"**Verbs**: {sorted(list(all_verbs))}\")\n",
        "print(f\"**Adjectives**: {sorted(list(all_adjectives))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBx0yTcXj233",
        "outputId": "16a354b8-d635-448c-b6e7-af6d5bef4a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sentence 1 ---: **Japan economy slides to recession. The Japanese economy has officially gone back into recession for the first time since 2001.**\n",
            "Token           POS        Dependency\n",
            "-----------------------------------\n",
            "Japan           PROPN      compound  \n",
            "economy         NOUN       compound  \n",
            "slides          NOUN       ROOT      \n",
            "to              ADP        prep      \n",
            "recession       NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "The             DET        det       \n",
            "Japanese        ADJ        amod      \n",
            "economy         NOUN       nsubj     \n",
            "has             AUX        aux       \n",
            "officially      ADV        advmod    \n",
            "gone            VERB       ROOT      \n",
            "back            ADV        advmod    \n",
            "into            ADP        prep      \n",
            "recession       NOUN       pobj      \n",
            "for             ADP        prep      \n",
            "the             DET        det       \n",
            "first           ADJ        amod      \n",
            "time            NOUN       pobj      \n",
            "since           SCONJ      prep      \n",
            "2001            NUM        pobj      \n",
            ".               PUNCT      punct     \n",
            "\n",
            "--- Sentence 2 ---: **Optimism remains over UK housing. The UK property market remains robust despite the recent slowdown.**\n",
            "Token           POS        Dependency\n",
            "-----------------------------------\n",
            "Optimism        NOUN       nsubj     \n",
            "remains         VERB       ROOT      \n",
            "over            ADP        prep      \n",
            "UK              PROPN      compound  \n",
            "housing         NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "The             DET        det       \n",
            "UK              PROPN      compound  \n",
            "property        NOUN       compound  \n",
            "market          NOUN       nsubj     \n",
            "remains         VERB       ROOT      \n",
            "robust          ADJ        acomp     \n",
            "despite         SCONJ      prep      \n",
            "the             DET        det       \n",
            "recent          ADJ        amod      \n",
            "slowdown        NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "\n",
            "--- Sentence 3 ---: **Lufthansa flies back to profit. German airline Lufthansa has returned to profit in 2004 after posting a loss in 2003.**\n",
            "Token           POS        Dependency\n",
            "-----------------------------------\n",
            "Lufthansa       PROPN      nsubj     \n",
            "flies           VERB       ROOT      \n",
            "back            ADV        advmod    \n",
            "to              ADP        prep      \n",
            "profit          NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "German          ADJ        amod      \n",
            "airline         NOUN       compound  \n",
            "Lufthansa       PROPN      nsubj     \n",
            "has             AUX        aux       \n",
            "returned        VERB       ROOT      \n",
            "to              ADP        prep      \n",
            "profit          NOUN       pobj      \n",
            "in              ADP        prep      \n",
            "2004            NUM        pobj      \n",
            "after           ADP        prep      \n",
            "posting         VERB       pcomp     \n",
            "a               DET        det       \n",
            "loss            NOUN       dobj      \n",
            "in              ADP        prep      \n",
            "2003            NUM        pobj      \n",
            ".               PUNCT      punct     \n",
            "\n",
            "--- Sentence 4 ---: **The quick brown fox jumps over the lazy dog.**\n",
            "Token           POS        Dependency\n",
            "-----------------------------------\n",
            "The             DET        det       \n",
            "quick           ADJ        amod      \n",
            "brown           ADJ        amod      \n",
            "fox             NOUN       nsubj     \n",
            "jumps           VERB       ROOT      \n",
            "over            ADP        prep      \n",
            "the             DET        det       \n",
            "lazy            ADJ        amod      \n",
            "dog             NOUN       pobj      \n",
            ".               PUNCT      punct     \n",
            "\n",
            "--- Sentence 5 ---: **A study found that 10% of users never log in.**\n",
            "Token           POS        Dependency\n",
            "-----------------------------------\n",
            "A               DET        det       \n",
            "study           NOUN       nsubj     \n",
            "found           VERB       ROOT      \n",
            "that            SCONJ      mark      \n",
            "10              NUM        nummod    \n",
            "%               NOUN       nsubj     \n",
            "of              ADP        prep      \n",
            "users           NOUN       pobj      \n",
            "never           ADV        neg       \n",
            "log             VERB       ccomp     \n",
            "in              ADP        prt       \n",
            ".               PUNCT      punct     \n",
            "\n",
            "### Extracted Parts of Speech ###\n",
            "**Nouns**: ['%', 'Japan', 'Lufthansa', 'Optimism', 'UK', 'airline', 'dog', 'economy', 'fox', 'housing', 'loss', 'market', 'profit', 'property', 'recession', 'slides', 'slowdown', 'study', 'time', 'users']\n",
            "**Verbs**: ['flies', 'found', 'gone', 'jumps', 'log', 'posting', 'remains', 'returned']\n",
            "**Adjectives**: ['German', 'Japanese', 'brown', 'first', 'lazy', 'quick', 'recent', 'robust']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "q2_sentences = [\n",
        "    \"My phone number is 1234567890 and my email is test@domain.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!! #Coding #Fun\"\n",
        "]\n",
        "\n",
        "\n",
        "for i, text in enumerate(q2_sentences):\n",
        "    print(f\"\\n--- Text {i+1}: '{text}' ---\")\n",
        "\n",
        "    phone_pattern = re.compile(r\"(\\+?\\d{1,3}[-. ]?)?\\(?\\d{3}\\)?[-. ]?\\d{3}[-. ]?\\d{4,}\")\n",
        "\n",
        "    found_phones = phone_pattern.findall(text)\n",
        "    print(f\"**Found Phone Numbers**: {found_phones}\")\n",
        "\n",
        "    email_pattern = re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\")\n",
        "    found_emails = email_pattern.findall(text)\n",
        "    print(f\"**Found Emails**: {found_emails}\")\n",
        "\n",
        "    url_pattern = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    found_urls = url_pattern.findall(text)\n",
        "    print(f\"**Found URLs**: {found_urls}\")\n",
        "\n",
        "    cleaned_text = phone_pattern.sub(\"\", text)\n",
        "    cleaned_text = email_pattern.sub(\"\", cleaned_text)\n",
        "    cleaned_text = url_pattern.sub(\"\", cleaned_text)\n",
        "\n",
        "    final_cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", cleaned_text)\n",
        "\n",
        "    print(f\"**Text After Removal**: {final_cleaned_text.strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFRkPX8Tj8Uf",
        "outputId": "364942e1-270b-478f-dc38-e54c6727401e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Text 1: 'My phone number is 1234567890 and my email is test@domain.com' ---\n",
            "**Found Phone Numbers**: ['']\n",
            "**Found Emails**: ['test@domain.com']\n",
            "**Found URLs**: []\n",
            "**Text After Removal**: My phone number is  and my email is\n",
            "\n",
            "--- Text 2: 'Visit https://example.com for more info!!!' ---\n",
            "**Found Phone Numbers**: []\n",
            "**Found Emails**: []\n",
            "**Found URLs**: ['https://example.com']\n",
            "**Text After Removal**: Visit  for more info\n",
            "\n",
            "--- Text 3: 'HELLO!!! This is SOOOOO exciting :))' ---\n",
            "**Found Phone Numbers**: []\n",
            "**Found Emails**: []\n",
            "**Found URLs**: []\n",
            "**Text After Removal**: HELLO This is SOOOOO exciting\n",
            "\n",
            "--- Text 4: 'Contact us at info@company.org or call +91 98765-43210' ---\n",
            "**Found Phone Numbers**: []\n",
            "**Found Emails**: ['info@company.org']\n",
            "**Found URLs**: []\n",
            "**Text After Removal**: Contact us at  or call 91 9876543210\n",
            "\n",
            "--- Text 5: 'Python's regex is very useful!!! #Coding #Fun' ---\n",
            "**Found Phone Numbers**: []\n",
            "**Found Emails**: []\n",
            "**Found URLs**: []\n",
            "**Text After Removal**: Pythons regex is very useful Coding Fun\n"
          ]
        }
      ]
    }
  ]
}